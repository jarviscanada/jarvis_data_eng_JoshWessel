{
  "metadata": {
    "name": "Spark Dataframe - WDI Data Analytics",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# SparkSession\n\nSparkSession is automatically created when you start up a Notebook (e.g. Zeppelin, Databricks)\n\n\u003cimg src\u003d\"https://i.imgur.com/5Ai45fb.jpg\" width\u003d500px\u003e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark\n//Scala SparkSession\nspark"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n#PySpark SparkSession\nspark"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show DataFrame\n\n`df.show()` is the Spark native API that displays data but it\u0027s not pretty. \n\n`z.show(df)` is a Zeppelin build-in feature that allows you to show a df result in a pretty way"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n#List all hive tables in a df\ntables_df \u003d spark.sql(\"show tables\")"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\ntables_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\nz.show(tables_df)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Spark SQL vs Dataframe\n\n`%sql` is the Spark SQL interpreter\n\n`%spark.pyspark` is the PySpark interpreter\n\n`%spark` is the Spark Scala interpreter"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nselect count(1) from wdi_csv_parquet"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n\n#Read Hive data to a df (this is lazy)\nwdi_df \u003d spark.sql(\"SELECT * from wdi_csv_parquet\")\n#Persist df in memory for fast futuer access\nwdi_df \u003d wdi_df.cache()\nwdi_df.printSchema()\n\n#Spark action is eager\nz.show(wdi_df.count())"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show Historical GDP for Canada\n\n- Re-write the hive query (left cell) using PySpark df"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT year, IndicatorValue as GDP\nFROM wdi_csv_parquet\nWHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 and countryName \u003d \u0027Canada\u0027\nORDER BY year\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 1\nwdi_canada_df1 \u003d spark.sql(\"SELECT year, indicatorValue FROM wdi_csv_parquet WHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 AND countryName \u003d \u0027Canada\u0027 ORDER BY year\")\n\n#use z.show to display df result and draw a bar chart\nz.show(wdi_canada_df1.select(\"year\", \"IndicatorValue\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 2\nwdi_canada_df2 \u003d wdi_df.select(\"year\", \"indicatorValue\").filter((wdi_df.indicatorcode \u003d\u003d \"NY.GDP.MKTP.KD.ZG\") \u0026 (wdi_df.countryname \u003d\u003d \"Canada\")).orderBy(\"year\")\nz.show(wdi_canada_df2)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n\n# Show GDP for Each County and Sort By Year\n\n- Re-write the hive query (left cell) using PySpark df  \n    - hint: you can create multiple DFs "
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nSELECT countryname,\n       year,\n       indicatorcode,\n       indicatorvalue\nFROM wdi_csv_parquet\nWHERE indicatorcode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027\nDISTRIBUTE BY countryname\nSORT BY countryname, year\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 1\nwdi_gdp_df1 \u003d wdi_df.select(\"countryName\",\"year\",\"indicatorCode\",\"indicatorValue\").filter(wdi_df[\u0027indicatorCode\u0027] \u003d\u003d \u0027NY.GDP.MKTP.KD.ZG\u0027).repartition(\"countryName\").orderBy([\"countryName\",\"year\"],ascending\u003d[1,1])\nz.show(wdi_gdp_df1)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 2\nwdi_gdp_df2 \u003d spark.sql(\"SELECT countryName, year, indicatorCode, indicatorValue FROM wdi_csv_parquet WHERE indicatorCode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 DISTRIBUTE BY countryName SORT BY countryName, year\")\nz.show(wdi_gdp_df2)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Find the highest GDP for each country\n\n- Re-write the hive query (left cell) using PySpark df\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n\nSELECT wdi_csv_parquet.indicatorvalue AS value, \n       wdi_csv_parquet.year           AS year, \n       wdi_csv_parquet.countryname    AS country \nFROM   (SELECT Max(indicatorvalue) AS ind, \n               countryname \n        FROM   wdi_csv_parquet \n        WHERE  indicatorcode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027 \n               AND indicatorvalue \u003c\u003e 0 \n        GROUP  BY countryname) t1 \n       INNER JOIN wdi_csv_parquet \n               ON t1.ind \u003d wdi_csv_parquet.indicatorvalue \n                  AND t1.countryname \u003d wdi_csv_parquet.countryname\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 1\nfrom pyspark.sql.functions import max as sparkMax\n\nwdi_high_gdp_df_inner \u003d wdi_df.filter((wdi_df.indicatorcode \u003d\u003d \"NY.GDP.MKTP.KD.ZG\") \u0026 (wdi_df.indicatorvalue !\u003d 0)).groupBy(\"countryName\").agg(sparkMax(\"indicatorValue\").alias(\"ind\")).select(\"ind\", wdi_df.countryname.alias(\"countryNameInner\"))\nwdi_high_gdp_df1 \u003d wdi_df.join(wdi_high_gdp_df_inner, (wdi_df.indicatorvalue \u003d\u003d wdi_high_gdp_df_inner.ind) \u0026 (wdi_df[\"countryName\"] \u003d\u003d wdi_high_gdp_df_inner.countryNameInner), \"inner\")\nwdi_high_gdp_df1 \u003d wdi_high_gdp_df1.select(wdi_high_gdp_df1[\"ind\"].alias(\"value\"),wdi_high_gdp_df1[\"year\"],wdi_high_gdp_df1[\"countryname\"].alias(\"country\"))\nz.show(wdi_high_gdp_df1)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# Approach 2\nwdi_high_gdp_df2 \u003d spark.sql(\"SELECT wdi_csv_parquet.indicatorvalue AS value, wdi_csv_parquet.year AS year, wdi_csv_parquet.countryname AS country FROM (SELECT MAX(indicatorvalue) AS ind, countryname FROM wdi_csv_parquet WHERE ((indicatorcode \u003d \u0027NY.GDP.MKTP.KD.ZG\u0027) AND (indicatorvalue !\u003d 0)) GROUP BY countryname) t1 INNER JOIN wdi_csv_parquet ON t1.ind \u003d wdi_csv_parquet.indicatorvalue AND t1.countryname \u003d wdi_csv_parquet.countryname\")\nz.show(wdi_high_gdp_df2)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n"
    }
  ]
}